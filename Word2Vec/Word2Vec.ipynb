{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "0da0635d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sukku\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\sukku\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sukku\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"punkt_tab\")\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "7ee59f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "220e9cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c4a70f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# 1) Load raw text\n",
    "corpus_text = \"\"\n",
    "for filename in os.listdir('data'):\n",
    "    if filename.endswith('.csv'):\n",
    "        df = pd.read_csv(os.path.join('data', filename), encoding='latin1')\n",
    "        corpus_text += \" \".join(df['x'].dropna().astype(str)) + \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e92be9a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165770"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b0888939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 1954\n"
     ]
    }
   ],
   "source": [
    "corpus_text = corpus_text.lower()\n",
    "corpus_text = re.sub(r\"\\[.*?\\]\", \"\", corpus_text)\n",
    "\n",
    "# 2) Sentence split BEFORE removing punctuation\n",
    "sents = sent_tokenize(corpus_text)\n",
    "print(f\"Number of sentences: {len(sents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "807dde9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usable sentences: 1194\n",
      "Sample: [['film', 'title', 'card', 'written', 'full', 'transcript', 'dreamworks', 'animations', 'fulllength', 'feature', 'film', 'kung', 'fu', 'panda'], ['narrator', 'po', 'legend', 'tells', 'legendary', 'warrior', 'whose', 'kung', 'fu', 'skills', 'stuff', 'legend'], ['traveled', 'land', 'search', 'worthy', 'foes']]\n"
     ]
    }
   ],
   "source": [
    "tokenized_sents = []\n",
    "for s in sents:\n",
    "    s_clean = re.sub(r\"[^a-zA-Z\\s]\", \"\", s)           # remove non-alpha\n",
    "    tokens = word_tokenize(s_clean)                      # tokenize\n",
    "    tokens = [t for t in tokens if t not in stop_words]  # remove stopwords\n",
    "    if len(tokens) >= 3:                                 # skip tiny sentences\n",
    "        tokenized_sents.append(tokens)\n",
    "\n",
    "print(f\"Usable sentences: {len(tokenized_sents)}\")\n",
    "print(f\"Sample: {tokenized_sents[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "346dfc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(\n",
    "    sentences=tokenized_sents,\n",
    "    vector_size=20,       # much smaller vectors for tiny corpus\n",
    "    window=3,             # smaller window\n",
    "    min_count=1,          # keep all words (data is tiny)\n",
    "    workers=4,\n",
    "    epochs=100,           # many more epochs\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "36ef73ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.build_vocab(tokenized_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "297990b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.train(tokenized_sents, total_examples=model.corpus_count, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "57ec588b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('revealed', 0.9386510252952576),\n",
       " ('size', 0.8791487812995911),\n",
       " ('legendary', 0.8772938847541809),\n",
       " ('white', 0.8594155311584473),\n",
       " ('among', 0.8496799468994141),\n",
       " ('true', 0.8477231860160828),\n",
       " ('become', 0.8448075652122498),\n",
       " ('warrior', 0.8419941663742065),\n",
       " ('hmm', 0.8319401741027832),\n",
       " ('real', 0.8228393793106079)]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('dragon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d3c1cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
